---
title: STAT 5443, HW3
author: Ariel Mundo
date: "`r Sys.Date()`"
output:
    prettydoc::html_pretty:
    pdf_document: 
    theme: cayman
    css: styles.css
---
<style type="text/css">

p {
   font-size: 18px;
}
code.r{
  font-size: 14px;
}
pre {
  font-size: 18px
}
</style>



```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
library(prettydoc)
```

## PROBLEM 1
### GIBBS SAMPLER

This section contains parts 1-4 from PROBLEM 1.
```{r, GIBBS SAMPLER, warning=FALSE}
library(plyr)
rm(list = ls())
set.seed(123)
alpha=2
beta_o=6.4
n=74
s_1=16
niter=1000
theta_init=s_1/n
s_init=s_1/n
  theta=rep(NA,niter)
  s=rep(NA,niter)
  theta[1] = theta_init
  s[1]=s_init
  for(i in 2:niter){
    s[i] = rbinom(1,size=n,prob=theta[i-1])
    theta[i] = rbeta(1,alpha+s[i],beta_o+n-s[i])
  }
  pmf<-count(s)
  pmf$vals<-pmf$freq/niter
 
```

```{r, FIG 1, fig.cap="Fig.1 Traceplot for theta"}
plot(theta,type="l", main='Traceplot for theta',xlab='iterations')
```
```{r, FIG 2, fig.cap="Fig.2 Traceplot for s"}
plot(s,type="l", main='Traceplot for s',xlab='iterations')
```

```{r, FIG 3, fig.cap="Fig.3 Approximate pmf"}
plot(x=pmf$x,y=pmf$vals, main='approximate pmf')
```
```{r, FIG 4, fig.cap="Barplot of s"}
hist(s,freq=FALSE, main='Barplot for s')
print(paste('posterior median of theta:',median(theta), 'MLE estimate',s_1/n))
```

**_The estimated posterior mean of $\theta$ is indeed close to the maximum likelihood estimate of s/n._**
 
### PART 5 OF PROBLEM 1

This section measures the sensitivity of the posterior median to the choice of initial values. For this part, the previous Gibbs sampler will be transformed in a function, and the initial ratio $s/n$ will be randomized and the median $s$ and $\theta$ will be plotted for all iterations.

```{r, PROBLEM 1 PART 5a, fig.cap="Traceplot of median theta using random values"}

binomial_beta_gibbs<-function(theta_init,s_init,iterations){
alpha=2
beta_o=6.4
n=74
  theta_init=s_1/n
s_init=s_1/n
  theta=rep(NA,iterations)
  s=rep(NA,iterations)
  theta[1] = theta_init
  s[1]=s_init
  for(i in 2:iterations){
    s[i] = rbinom(1,size=n,prob=theta[i-1]) #conditional for s
    theta[i] = rbeta(1,alpha+s[i],beta_o+n-s[i]) #conditional for theta
  }
  pmf<-count(s)
  pmf$vals<-pmf$freq/niter
 return(cbind(median(s),median(theta)))
}
#v<-seq(0,10,0.1)
v<-runif(1000)
test<-matrix(NA,2,length(v))
for (j in 1:length(v)){
test[,j]<-binomial_beta_gibbs(v[j],v[j],1000)
}
```

```{r, FIG 5, fig.cap="Fig.5 Median theta from variable initial values"}

plot(test[2,], type='l', xlab='iteration',main='median theta from variable initial values') #plotting the median values of all iterations
```


```{r, FIG 6, fig.cap="Fig. 6 Traceplot for median s from variable initial values"}


plot(test[1,], type='l', xlab='iteration',main='median s from variable initial values') #plotting the median values of all iterations

```

**_Based on these results, the posterior median is relatively insensitive to the choice of initial values, as a randomization of the initial values for theta and s (based on the traceplots) results in a posterior  median of theta that is close to the posterior estimated in problem 1._**

***

### PROBLEM 2

The pmf in this case is the result of the combination of each individual distribution:

${n\choose s} \theta^{s}(1-\theta)^{n-s} \frac{\Gamma(\alpha_0+\beta_0)}{\Gamma(\alpha_0)\Gamma(\beta_0)}\theta^{\alpha_0-1}(1-\theta)^{\beta_0-1}\left[\frac{\exp(-\lambda)\lambda^{n}}{n!})\right]$

This can be re-written as:
$\frac{n!}{s!(n-s!)}\theta^{s}(1-\theta)^{n-s} \frac{\Gamma(\alpha_0+\beta_0)}{\Gamma(\alpha_0)\Gamma(\beta_0)}\theta^{\alpha_0-1}(1-\theta)^{\beta_0-1}\left[\frac{\exp(-\lambda)\lambda^{n}}{n!})\right]$


For $\theta \vert s,n \propto \theta^{\alpha_0+s-1}(1-\theta)^{n-s+\beta_0-1} \propto Beta(\alpha_0+s,n-s+\beta_0)$

For $s \vert \theta,n \propto {n\choose s} \theta^{s}(1-\theta)^{n-s} \propto Binomial (n,\theta)$

Therefore the two terms $n!$ cancel out and the exponential can be taken out as it is a constant.

Writing the conditional distribution of $n$ by considering only the terms that include it and omitting constant terms:
$f(n\vert\theta,s) \propto \frac{\lambda^{n}(1-\theta)^{n-s}}{(n-s)!}$

Which, considering a constant $\exp (-\lambda(1-\theta))$ means that $(n-s) \propto Poisson(\lambda(1-\theta))$ 



```{r, PROBLEM 2}
n_1=74
binomial_beta_gibbs_poisson<-function(n_init,theta_init,s_init,iterations){
alpha=2
beta_o=6.4
lambda=64
  theta_bgp=rep(NA,iterations)
  s_bgp=rep(NA,iterations)
  n_bgp=rep(NA,iterations)
    theta_bgp[1] = theta_init
    s_bgp[1]=s_init
    n_bgp[1]=n_init
  for(i in 2:iterations){
    s_bgp[i] = rbinom(1,size=n_bgp[i-1],prob=theta_bgp[i-1])
    theta_bgp[i] = rbeta(1,alpha+s_bgp[i],beta_o+n_bgp[i-1]-s_bgp[i])
    n_bgp[i]=s_bgp[i]+rpois(1,lambda*(1-theta_bgp[i])) #conditional for n
  }
  #pmf<-count(s)
  #pmf$vals<-pmf$freq/niter
 return(cbind(s_bgp,theta_bgp,n_bgp)) #storing the values
}

test2<-binomial_beta_gibbs_poisson(10,s_1/n_1,s_1/n_1,1000)

```
```{r, FIG 7, fig.cap="Fig.7 Barplot of s"}
hist(test2[,1],freq=FALSE, main='Barplot of s')
print(paste('Median theta of Binomial-Beta-Poisson',median(test2[,2]),'The posterior median is similar to the method of problem 1'))
```
Regarding convergence, plotting the traceplot for $s$ and $\theta$:

```{r, FIG 8, fig.cap="Fig.8 Traceplot for s"}
plot(test2[,1], type='l',main='traceplot for s', xlab='iterations')
```

```{r, FIG 9, fig.cap="Fig.9 Traceplot for theta"}
plot(test2[,2], type='l',main='traceplot for theta', xlab='iterations')
``` 

**_This indicates that the convergence is similar to the values from problem 1, as the traceplots show a similar range of values in both cases_. (Figs. 1,2,8,9)**
