---
title: STAT 5443, FINAL PROJECT
author: Ariel Mundo
date: "`r Sys.Date()`"
output:
    prettydoc::html_pretty:
    pdf_document: 
    theme: cayman
    css: styles.css
---
<style type="text/css">

p {
   font-size: 18px;
}
code.r{
  font-size: 14px;
}
pre {
  font-size: 18px
}
</style>

## Sparse Classification 

### Comparing penalized methods for High-dimensional Classification

We would like to compare the performance of several modern regression methods including penalized regression methods such as LASSO and Elastic Net regression with 10-fold cross-validation. 

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
library(prettydoc)
```

Library hdrm was installed following the directions from:
https://github.com/pbreheny/hdrm


```{r, loading data}

library(hdrm)
library(glmnet)
downloadData(Golub1999)
attachData(Golub1999)
```
http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/#computing-penalized-logistic-regression



```{r, splitting the data}
n=nrow(X)

#split in train and test sets
set.seed(1234)
train_rows <- sample(1:n, n/2)
X.train <- X[train_rows, ]
X.test <- X[-train_rows, ]

y.train <- y[train_rows]
y.test <- y[-train_rows]

```

```{r,Cl}

logistic_l1<-glmnet(x=X.train,y=y.train,family = "binomial")
plot(logistic_l1)
 grid=10^seq(10,-2,length=100)
lasso.mod =glmnet (X.train, y.train, alpha = 1, lambda = grid)
plot(lasso.mod)

```
https://daviddalpiaz.github.io/stat432sp18/hw/hw07-soln.html
https://stackoverflow.com/questions/20572919/finding-misclassification-rate-in-r-loan-default

```{r, ELASTIC NET, LASSO AND RIDGE}
#cross validation

alpha=0.5
#Using cross validation for best lambda in all models
fit.elastic_net<-cv.glmnet(X.train,y.train,family="binomial",type.measure = "class",alpha=alpha)
fit.lasso<-cv.glmnet(X.train,y.train,family="binomial",type.measure = "class",alpha=1)
fit.ridge<-cv.glmnet(X.train,y.train,family="binomial",type.measure = "class",alpha=0)
par(mfrow=c(2,2))
plot(fit.elastic_net, main="Elastic net")
plot(fit.lasso, main="Lasso")
plot(fit.ridge, main="Ridge")
par(mfrow=c(1,1))

#Fitting the models to the training data

mod.enet<-glmnet(X.train,y.train,alpha=0.5,family = "binomial",lambda=fit.elastic_net$lambda.min)
mod.lasso<-glmnet(X.train,y.train,alpha=1,family = "binomial",lambda=fit.lasso$lambda.min)
mod.ridge<-glmnet(X.train,y.train,alpha=0,family = "binomial",lambda=fit.ridge$lambda.min)

#Extracting non-zero coefficients for each model
coef.enet<-as.factor(rownames(coef(mod.enet, s = 'lambda.min'))[coef(mod.enet, s = 'lambda.min')[,1]!= 0])
coef.lasso<-as.factor(rownames(coef(mod.lasso, s = 'lambda.min'))[coef(mod.lasso, s = 'lambda.min')[,1]!= 0])
coef.ridge<-as.factor(rownames(coef(mod.ridge, s = 'lambda.min'))[coef(mod.ridge, s = 'lambda.min')[,1]!= 0])

#Predictions on training data
prob.enet<-mod.enet %>%predict(newx=X.test)
prob.lasso<-mod.lasso %>%predict(newx=X.test)
prob.ridge<-mod.ridge %>%predict(newx=X.test)

pred.class.enet<-ifelse(prob.enet>0.5,"AML","ALL")
pred.class.lasso<-ifelse(prob.lasso>0.5,"AML","ALL")
pred.class.ridge<-ifelse(prob.ridge>0.5,"AML","ALL")
#Accuracy
mean(pred.class.enet==y.test)
mean(pred.class.lasso==y.test)
mean(pred.class.ridge==y.test)
```

